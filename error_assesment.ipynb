{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from data_load import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "series,times = load_dataset('data_h')\n",
    "series = series.reshape(-1,1) #array bidimensional para utilizar luego el MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0.1,1)) # los valores de la loss function son menoros con este rango que con (0,1)\n",
    "series_scaled = scaler.fit_transform(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.7\n",
    "val_percent = 0.2\n",
    "test_percent = 0.1\n",
    "\n",
    "train_size = int(len(series) * train_percent)\n",
    "val_size = int(len(series) * val_percent)\n",
    "\n",
    "x_train = series[:train_size]\n",
    "x_train_scaled = series_scaled[:train_size]\n",
    "time_train = times[:train_size]\n",
    "\n",
    "x_val = series[train_size:train_size + val_size]\n",
    "x_val_scaled = series_scaled[train_size:train_size + val_size]\n",
    "time_val = times[train_size:train_size + val_size]\n",
    "\n",
    "x_test = series[train_size + val_size:]\n",
    "x_test_scaled = series_scaled[train_size + val_size:]\n",
    "time_test = times[train_size + val_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a considerar los 3 mejores modelos: \n",
    "\n",
    "* Bidirectional_LSTM_alt ws=96 bs=16\n",
    "* LSTM_Stacked_3_alt ws=96 bs=16\n",
    "* LSTM_Stacked_3 ws=96 bs=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_34\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_34\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_73 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m16,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_74 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_75 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">95,489</span> (373.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m95,489\u001b[0m (373.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">95,489</span> (373.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m95,489\u001b[0m (373.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir el nombre y la ruta del archivo del modelo guardado\n",
    "model_name = 'LSTM_stacked_3_ws96_bs32.keras'\n",
    "checkpoint_dir = 'Results/train_LSTM_stacked_3_ws96_bs32_results'\n",
    "checkpoint_filepath = os.path.join(checkpoint_dir, model_name)\n",
    "\n",
    "model = tf.keras.models.load_model(checkpoint_filepath, compile=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 24 * 4 # 4 days\n",
    "num_features = 1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "train_generator = TimeseriesGenerator(x_train_scaled, \n",
    "                                      x_train_scaled, # Esta bien utilizar la demanda como entrada y como objetivo a la vez ya que es una prediccion univariada\n",
    "                                      length=window_size,\n",
    "                                      batch_size=batch_size)\n",
    "\n",
    "validation_generator = TimeseriesGenerator(x_val_scaled,\n",
    "                                           x_val_scaled,\n",
    "                                           length=window_size,\n",
    "                                           batch_size=batch_size)\n",
    "\n",
    "# normalizamos tambien los datos de test ya que el modelo estara entrenado con datos normalizados por lo que no sera muy consistente realizarlo sin normalizar\n",
    "test_generator = TimeseriesGenerator(x_test_scaled,\n",
    "                                           x_test_scaled,\n",
    "                                           length=window_size,\n",
    "                                           batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  5/189\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 33ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daviddpp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step\n",
      "\u001b[1m 8/52\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daviddpp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "\u001b[1m 7/25\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daviddpp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "from models import predict\n",
    "\n",
    "train_predict = predict(model,\n",
    "                        train_generator,\n",
    "                        scaler)\n",
    "\n",
    "val_predict = predict(model,\n",
    "                       validation_generator,\n",
    "                       scaler)\n",
    "\n",
    "test_predict = predict(model,\n",
    "                       test_generator,\n",
    "                       scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de Errores Absolutos:\n",
      "Min.    0.002\n",
      "1st Qu. 9.174\n",
      "Median  20.988\n",
      "Mean    30.174\n",
      "3rd Qu. 43.435\n",
      "Max.    332.234\n"
     ]
    }
   ],
   "source": [
    "errors_abs_train = np.abs(x_train[window_size:,0] - train_predict[:, 0])\n",
    "\n",
    "min_abs_error = np.min(errors_abs_train)\n",
    "q1_abs_error = np.percentile(errors_abs_train, 25)\n",
    "median_abs_error = np.median(errors_abs_train)\n",
    "mean_abs_error = np.mean(errors_abs_train)\n",
    "q3_abs_error = np.percentile(errors_abs_train, 75)\n",
    "max_abs_error = np.max(errors_abs_train)\n",
    "\n",
    "print(\"Estadísticas de Errores Absolutos:\")\n",
    "print(f\"Min.    {min_abs_error:.3f}\")\n",
    "print(f\"1st Qu. {q1_abs_error:.3f}\")\n",
    "print(f\"Median  {median_abs_error:.3f}\")\n",
    "print(f\"Mean    {mean_abs_error:.3f}\")\n",
    "print(f\"3rd Qu. {q3_abs_error:.3f}\")\n",
    "print(f\"Max.    {max_abs_error:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de Errores Absolutos:\n",
      "Min.    0.093\n",
      "1st Qu. 13.058\n",
      "Median  30.369\n",
      "Mean    39.809\n",
      "3rd Qu. 57.238\n",
      "Max.    225.939\n"
     ]
    }
   ],
   "source": [
    "errors_abs_test = np.abs(x_test[window_size:,0] - test_predict[:, 0])\n",
    "\n",
    "min_abs_error = np.min(errors_abs_test)\n",
    "q1_abs_error = np.percentile(errors_abs_test, 25)\n",
    "median_abs_error = np.median(errors_abs_test)\n",
    "mean_abs_error = np.mean(errors_abs_test)\n",
    "q3_abs_error = np.percentile(errors_abs_test, 75)\n",
    "max_abs_error = np.max(errors_abs_test)\n",
    "\n",
    "print(\"Estadísticas de Errores Absolutos:\")\n",
    "print(f\"Min.    {min_abs_error:.3f}\")\n",
    "print(f\"1st Qu. {q1_abs_error:.3f}\")\n",
    "print(f\"Median  {median_abs_error:.3f}\")\n",
    "print(f\"Mean    {mean_abs_error:.3f}\")\n",
    "print(f\"3rd Qu. {q3_abs_error:.3f}\")\n",
    "print(f\"Max.    {max_abs_error:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daviddpp\\AppData\\Local\\Temp\\ipykernel_36944\\1210231178.py:1: RuntimeWarning: divide by zero encountered in divide\n",
      "  errors_mape_train = errors_abs_train / x_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de Errores Absolutos:\n",
      "Min.    0.000\n",
      "1st Qu. 0.069\n",
      "Median  0.176\n",
      "Mean    inf\n",
      "3rd Qu. 0.400\n",
      "Max.    inf\n"
     ]
    }
   ],
   "source": [
    "errors_mape_train = errors_abs_train / x_train\n",
    "\n",
    "min_abs_error = np.min(errors_mape_train)\n",
    "q1_abs_error = np.percentile(errors_mape_train, 25)\n",
    "median_abs_error = np.median(errors_mape_train)\n",
    "mean_abs_error = np.mean(errors_mape_train)\n",
    "q3_abs_error = np.percentile(errors_mape_train, 75)\n",
    "max_abs_error = np.max(errors_mape_train)\n",
    "\n",
    "print(\"Estadísticas de Errores Absolutos:\")\n",
    "print(f\"Min.    {min_abs_error:.3f}\")\n",
    "print(f\"1st Qu. {q1_abs_error:.3f}\")\n",
    "print(f\"Median  {median_abs_error:.3f}\")\n",
    "print(f\"Mean    {mean_abs_error:.3f}\")\n",
    "print(f\"3rd Qu. {q3_abs_error:.3f}\")\n",
    "print(f\"Max.    {max_abs_error:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de Errores Absolutos:\n",
      "Min.    0.000\n",
      "1st Qu. 0.085\n",
      "Median  0.209\n",
      "Mean    inf\n",
      "3rd Qu. 0.451\n",
      "Max.    inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daviddpp\\AppData\\Local\\Temp\\ipykernel_36944\\435371747.py:1: RuntimeWarning: divide by zero encountered in divide\n",
      "  errors_mape_test = errors_abs_test / x_test\n"
     ]
    }
   ],
   "source": [
    "errors_mape_test = errors_abs_test / x_test\n",
    "\n",
    "min_abs_error = np.min(errors_mape_test)\n",
    "q1_abs_error = np.percentile(errors_mape_test, 25)\n",
    "median_abs_error = np.median(errors_mape_test)\n",
    "mean_abs_error = np.mean(errors_mape_test)\n",
    "q3_abs_error = np.percentile(errors_mape_test, 75)\n",
    "max_abs_error = np.max(errors_mape_test)\n",
    "\n",
    "print(\"Estadísticas de Errores Absolutos:\")\n",
    "print(f\"Min.    {min_abs_error:.3f}\")\n",
    "print(f\"1st Qu. {q1_abs_error:.3f}\")\n",
    "print(f\"Median  {median_abs_error:.3f}\")\n",
    "print(f\"Mean    {mean_abs_error:.3f}\")\n",
    "print(f\"3rd Qu. {q3_abs_error:.3f}\")\n",
    "print(f\"Max.    {max_abs_error:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
